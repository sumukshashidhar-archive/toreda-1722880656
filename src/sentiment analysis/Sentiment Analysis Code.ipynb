{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Sentiment Analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumukshashidhar/toreda/blob/master/src/sentiment%20analysis/Sentiment%20Analysis%20Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_1IK3VFnidE",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis Beta "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKUGSvDIncSG",
        "colab_type": "text"
      },
      "source": [
        "First, install the dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFCGc-5JTMEb",
        "colab_type": "code",
        "outputId": "1f6b2831-604b-4af7-f871-88b2de408f75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install vaderSentiment\n",
        "!pip install newspaper3k"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vaderSentiment\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/fc/310e16254683c1ed35eeb97386986d6c00bc29df17ce280aed64d55537e9/vaderSentiment-3.3.2-py2.py3-none-any.whl (125kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 16.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 6.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n",
            "Collecting newspaper3k\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/b9/51afecb35bb61b188a4b44868001de348a0e8134b4dfa00ffc191567c4b9/newspaper3k-0.2.8-py3-none-any.whl (211kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 7.9MB/s \n",
            "\u001b[?25hCollecting feedfinder2>=0.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/35/82/1251fefec3bb4b03fd966c7e7f7a41c9fc2bb00d823a34c13f847fd61406/feedfinder2-0.0.4.tar.gz\n",
            "Collecting cssselect>=0.9.2\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.8.1)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.13)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.2.5)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.2.6)\n",
            "Collecting tinysegmenter==0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/17/82/86982e4b6d16e4febc79c2a1d68ee3b707e8a020c5d2bc4af8052d0f136a/tinysegmenter-0.3.tar.gz\n",
            "Collecting tldextract>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/0e/9ab599d6e78f0340bb1d1e28ddeacb38c8bb7f91a1b0eae9a24e9603782f/tldextract-2.2.2-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.6.3)\n",
            "Collecting jieba3k>=0.35.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/cb/2c8332bcdc14d33b0bedd18ae0a4981a069c3513e445120da3c3f23a8aaa/jieba3k-0.35.1.zip (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 12.9MB/s \n",
            "\u001b[?25hCollecting feedparser>=5.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/d8/7d37fec71ff7c9dbcdd80d2b48bcdd86d6af502156fc93846fb0102cb2c4/feedparser-5.2.1.tar.bz2 (192kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 45.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.23.0)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.12.0)\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/77/86/cdb5e8eaed90796aa83a6d9f75cfbd37af553c47a291cd47bc410ef9bdb2/requests_file-1.5.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.6/dist-packages (from tldextract>=2.0.1->newspaper3k) (2.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from tldextract>=2.0.1->newspaper3k) (46.4.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
            "Building wheels for collected packages: feedfinder2, tinysegmenter, jieba3k, feedparser\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-cp36-none-any.whl size=3357 sha256=6d7cd377eb8bac30ad15633d87b42c9ef2149ced5589e43344aebd07d0d5f4ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/03/ca/778e3a7a627e3d98836cc890e7cb40c7575424cfd3340f40ed\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-cp36-none-any.whl size=13539 sha256=f89b96ab4b561163be3183a607ecad207e458bf529de284d457653dc18d2274c\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/2b/43/a02ede72324dd40cdd7ca53aad718c7710628e91b8b0dc0f02\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-cp36-none-any.whl size=7398406 sha256=0a5c4cc0f76827964f6b434ab35b36925bc2626424cd8a5645a2ba27eff6f51e\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/15/9c/a3f1f67e7f7181170ad37d32e503c35da20627c013f438ed34\n",
            "  Building wheel for feedparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedparser: filename=feedparser-5.2.1-cp36-none-any.whl size=44940 sha256=584fe7587ce2b7c32fbb7fcd6ef44857a69ebef57ff6647b73530e1abdbb7131\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/69/b7/f52763c41c5471df57703a0ef718a32a5e81ee35dcf6d4f97f\n",
            "Successfully built feedfinder2 tinysegmenter jieba3k feedparser\n",
            "Installing collected packages: feedfinder2, cssselect, tinysegmenter, requests-file, tldextract, jieba3k, feedparser, newspaper3k\n",
            "Successfully installed cssselect-1.1.0 feedfinder2-0.0.4 feedparser-5.2.1 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 tinysegmenter-0.3 tldextract-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD80tUePn1SI",
        "colab_type": "text"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ5VRpUjSzlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import json\n",
        "import time\n",
        "import re\n",
        "import requests\n",
        "import nltk\n",
        "import argparse\n",
        "import logging\n",
        "import string\n",
        "import plotly.express as px\n",
        "try:\n",
        "    import urllib.parse as urlparse\n",
        "except ImportError:\n",
        "    import urlparse\n",
        "from tweepy.streaming import StreamListener\n",
        "from tweepy import API, Stream, OAuthHandler, TweepError\n",
        "from textblob import TextBlob\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "from random import randint, randrange\n",
        "from datetime import datetime\n",
        "from newspaper import Article, ArticleException"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-i45yNXn8Hy",
        "colab_type": "text"
      },
      "source": [
        "Defining some constants here, such as the sentiment url and list of tweet_ids that we wish to use for analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqBmM7j6S6lu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentimentURL = 'http://text-processing.com/api/sentiment/'\n",
        "\n",
        "\n",
        "# tweet id list\n",
        "tweet_ids = []\n",
        "\n",
        "\n",
        "prev_time = time.time()\n",
        "sentiment_avg = [0.0,0.0,0.0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBxEO1VlpABw",
        "colab_type": "text"
      },
      "source": [
        "This is the code that allows us to recieve sentiment analysis data from the API specified"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISSsrh22S-Eb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sentiment_from_url(text, sentimentURL):\n",
        "    # get sentiment from text processing website\n",
        "    payload = {'text': text}\n",
        "\n",
        "    try:\n",
        "        #logger.debug(text)\n",
        "        post = requests.post(sentimentURL, data=payload)\n",
        "        #logger.debug(post.status_code)\n",
        "        #logger.debug(post.text)\n",
        "    except requests.exceptions.RequestException as re:\n",
        "        logger.error(\"Exception: requests exception getting sentiment from url caused by %s\" % re)\n",
        "        raise\n",
        "\n",
        "    # return None if we are getting throttled or other connection problem\n",
        "    if post.status_code != 200:\n",
        "        logger.warning(\"Can't get sentiment from url caused by %s %s\" % (post.status_code, post.text))\n",
        "        return None\n",
        "\n",
        "    response = post.json()\n",
        "\n",
        "    neg = response['probability']['neg']\n",
        "    pos = response['probability']['pos']\n",
        "    neu = response['probability']['neutral']\n",
        "    label = response['label']\n",
        "\n",
        "    # determine if sentiment is positive, negative, or neutral\n",
        "    if label == \"neg\":\n",
        "        sentiment = \"negative\"\n",
        "    elif label == \"neutral\":\n",
        "        sentiment = \"neutral\"\n",
        "    else:\n",
        "        sentiment = \"positive\"\n",
        "\n",
        "    return sentiment, neg, pos, neu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF_CJVGFpHE9",
        "colab_type": "text"
      },
      "source": [
        "Test case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7VTIC85TDJD",
        "colab_type": "code",
        "outputId": "d462d5aa-40d3-4d48-dd4d-76508d189255",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_sentiment_from_url(\"I hate you\", sentimentURL)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('negative', 0.7400333317066653, 0.2599666682933347, 0.043876766913714414)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2aEfWHtpJT2",
        "colab_type": "text"
      },
      "source": [
        "Removing parts of speech and non essential parts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmuI1TsYVNqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "    # clean up text\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    text = re.sub(r\"https?\\S+\", \"\", text)\n",
        "    text = re.sub(r\"&.*?;\", \"\", text)\n",
        "    text = re.sub(r\"<.*?>\", \"\", text)\n",
        "    text = text.replace(\"RT\", \"\")\n",
        "    text = text.replace(u\"…\", \"\")\n",
        "    text = text.strip()\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASUahJLbpRlB",
        "colab_type": "text"
      },
      "source": [
        "Some more cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R9mBL7-VM7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text_sentiment(text):\n",
        "    # clean up text for sentiment analysis\n",
        "    text = re.sub(r\"[#|@]\\S+\", \"\", text)\n",
        "    text = text.strip()\n",
        "    return text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joTlKrkUpm1m",
        "colab_type": "text"
      },
      "source": [
        "Main Analysis Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsYjjeHWUFfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentiment_analysis(text):\n",
        "    \"\"\"Determine if sentiment is positive, negative, or neutral\n",
        "    algorithm to figure out if sentiment is positive, negative or neutral\n",
        "    uses sentiment polarity from TextBlob, VADER Sentiment and\n",
        "    sentiment from text-processing URL\n",
        "    \"\"\"\n",
        "\n",
        "    # pass text into sentiment url\n",
        "    if True:\n",
        "        ret = get_sentiment_from_url(text, sentimentURL)\n",
        "        if ret is None:\n",
        "            sentiment_url = None\n",
        "        else:\n",
        "            sentiment_url, neg_url, pos_url, neu_url = ret\n",
        "    else:\n",
        "        sentiment_url = None\n",
        "\n",
        "    # pass text into TextBlob\n",
        "    text_tb = TextBlob(text)\n",
        "\n",
        "    # pass text into VADER Sentiment\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    text_vs = analyzer.polarity_scores(text)\n",
        "\n",
        "    # determine sentiment from our sources\n",
        "    if sentiment_url is None:\n",
        "        #threshold values\n",
        "        if text_tb.sentiment.polarity < 0 and text_vs['compound'] <= -0.05:\n",
        "            sentiment = \"negative\"\n",
        "        elif text_tb.sentiment.polarity > 0 and text_vs['compound'] >= 0.05:\n",
        "            sentiment = \"positive\"\n",
        "        else:\n",
        "            sentiment = \"neutral\"\n",
        "    else:\n",
        "        # this works if the above function executes properly\n",
        "        if text_tb.sentiment.polarity < 0 and text_vs['compound'] <= -0.05 and sentiment_url == \"negative\":\n",
        "            sentiment = \"negative\"\n",
        "        elif text_tb.sentiment.polarity > 0 and text_vs['compound'] >= 0.05 and sentiment_url == \"positive\":\n",
        "            sentiment = \"positive\"\n",
        "        else:\n",
        "            sentiment = \"neutral\"\n",
        "\n",
        "    polarity = (text_tb.sentiment.polarity + text_vs['compound']) / 2\n",
        "\n",
        "    # output sentiment polarity\n",
        "    print(\"************\")\n",
        "    print(\"Sentiment Polarity: \" + str(round(polarity, 3)))\n",
        "\n",
        "    # output sentiment subjectivity (TextBlob)\n",
        "    print(\"Sentiment Subjectivity: \" + str(round(text_tb.sentiment.subjectivity, 3)))\n",
        "    # output sentiment\n",
        "    print(\"Sentiment (url): \" + str(sentiment_url))\n",
        "    print(\"Sentiment (algorithm): \" + str(sentiment))\n",
        "    print(\"Overall sentiment (textblob): \", text_tb.sentiment)\n",
        "    print(\"Overall sentiment (vader): \", text_vs)\n",
        "    print(\"sentence was rated as \", round(text_vs['neg']*100, 3), \"% Negative\")\n",
        "    print(\"sentence was rated as \", round(text_vs['neu']*100, 3), \"% Neutral\")\n",
        "    print(\"sentence was rated as \", round(text_vs['pos']*100, 3), \"% Positive\")\n",
        "    print(\"************\")\n",
        "    fig = px.bar(x = ['Negative', 'Positive', 'Neutral'], y=[text_vs['neg']*100, text_vs['pos']*100, text_vs['neu']*100], width=500)\n",
        "    fig.show()\n",
        "    return polarity, text_tb.sentiment.subjectivity, sentiment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBw_-un_UQFV",
        "colab_type": "code",
        "outputId": "8f0efeac-d7e2-497c-b80c-2abd53dbd941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        }
      },
      "source": [
        "sentiment_analysis(\"Sumuk Shashidhar is the best in tHIS world\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "************\n",
            "Sentiment Polarity: 0.818\n",
            "Sentiment Subjectivity: 0.3\n",
            "Sentiment (url): neutral\n",
            "Sentiment (algorithm): neutral\n",
            "Overall sentiment (textblob):  Sentiment(polarity=1.0, subjectivity=0.3)\n",
            "Overall sentiment (vader):  {'neg': 0.0, 'neu': 0.625, 'pos': 0.375, 'compound': 0.6369}\n",
            "sentence was rated as  0.0 % Negative\n",
            "sentence was rated as  62.5 % Neutral\n",
            "sentence was rated as  37.5 % Positive\n",
            "************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"d7c09dac-039a-4fe9-9456-aa8da9c6c8e4\" class=\"plotly-graph-div\" style=\"height:525px; width:500px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"d7c09dac-039a-4fe9-9456-aa8da9c6c8e4\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'd7c09dac-039a-4fe9-9456-aa8da9c6c8e4',\n",
              "                        [{\"alignmentgroup\": \"True\", \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"x=%{x}<br>y=%{y}\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\"}, \"name\": \"\", \"offsetgroup\": \"\", \"orientation\": \"v\", \"showlegend\": false, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"Negative\", \"Positive\", \"Neutral\"], \"xaxis\": \"x\", \"y\": [0.0, 37.5, 62.5], \"yaxis\": \"y\"}],\n",
              "                        {\"barmode\": \"relative\", \"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"width\": 500, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"x\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"y\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d7c09dac-039a-4fe9-9456-aa8da9c6c8e4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.81845, 0.3, 'neutral')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtHgbOXEpvwY",
        "colab_type": "text"
      },
      "source": [
        "Under Development"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84wDTTBQUTXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_page_text(url):\n",
        "\n",
        "    max_paragraphs = 10\n",
        "\n",
        "    try:\n",
        "        logger.debug(url)\n",
        "        req = requests.get(url)\n",
        "        html = req.text\n",
        "        soup = BeautifulSoup(html, 'html.parser')\n",
        "        html_p = soup.findAll('p')\n",
        "\n",
        "        logger.debug(html_p)\n",
        "\n",
        "        if html_p:\n",
        "            n = 1\n",
        "            for i in html_p:\n",
        "                if n <= max_paragraphs:\n",
        "                    if i.string is not None:\n",
        "                        logger.debug(i.string)\n",
        "                        yield i.string\n",
        "                n += 1\n",
        "\n",
        "    except requests.exceptions.RequestException as re:\n",
        "        logger.warning(\"Exception: can't crawl web site (%s)\" % re)\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}